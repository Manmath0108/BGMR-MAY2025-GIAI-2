{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1779,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16863406408094436,
      "grad_norm": 1.7540156841278076,
      "learning_rate": 4.721753794266442e-05,
      "loss": 2.7305,
      "step": 100
    },
    {
      "epoch": 0.3372681281618887,
      "grad_norm": 1.9051939249038696,
      "learning_rate": 4.440697020798201e-05,
      "loss": 2.6557,
      "step": 200
    },
    {
      "epoch": 0.5059021922428331,
      "grad_norm": 1.8088945150375366,
      "learning_rate": 4.159640247329961e-05,
      "loss": 2.5726,
      "step": 300
    },
    {
      "epoch": 0.6745362563237775,
      "grad_norm": 2.154707908630371,
      "learning_rate": 3.8785834738617206e-05,
      "loss": 2.7429,
      "step": 400
    },
    {
      "epoch": 0.8431703204047217,
      "grad_norm": 2.143183469772339,
      "learning_rate": 3.59752670039348e-05,
      "loss": 2.5194,
      "step": 500
    },
    {
      "epoch": 1.0118043844856661,
      "grad_norm": 1.9595532417297363,
      "learning_rate": 3.316469926925239e-05,
      "loss": 2.5675,
      "step": 600
    },
    {
      "epoch": 1.1804384485666104,
      "grad_norm": 2.4032082557678223,
      "learning_rate": 3.0354131534569984e-05,
      "loss": 2.5155,
      "step": 700
    },
    {
      "epoch": 1.3490725126475547,
      "grad_norm": 2.9284684658050537,
      "learning_rate": 2.754356379988758e-05,
      "loss": 2.4486,
      "step": 800
    },
    {
      "epoch": 1.5177065767284992,
      "grad_norm": 2.857816219329834,
      "learning_rate": 2.4732996065205173e-05,
      "loss": 2.5437,
      "step": 900
    },
    {
      "epoch": 1.6863406408094435,
      "grad_norm": 2.4752731323242188,
      "learning_rate": 2.1922428330522768e-05,
      "loss": 2.4913,
      "step": 1000
    },
    {
      "epoch": 1.8549747048903877,
      "grad_norm": 2.9491565227508545,
      "learning_rate": 1.9111860595840363e-05,
      "loss": 2.4727,
      "step": 1100
    },
    {
      "epoch": 2.0236087689713322,
      "grad_norm": 2.6791064739227295,
      "learning_rate": 1.6301292861157954e-05,
      "loss": 2.518,
      "step": 1200
    },
    {
      "epoch": 2.1922428330522767,
      "grad_norm": 2.8438916206359863,
      "learning_rate": 1.3490725126475547e-05,
      "loss": 2.5087,
      "step": 1300
    },
    {
      "epoch": 2.360876897133221,
      "grad_norm": 2.902982711791992,
      "learning_rate": 1.0680157391793142e-05,
      "loss": 2.4393,
      "step": 1400
    },
    {
      "epoch": 2.5295109612141653,
      "grad_norm": 2.8046841621398926,
      "learning_rate": 7.869589657110737e-06,
      "loss": 2.3968,
      "step": 1500
    },
    {
      "epoch": 2.6981450252951094,
      "grad_norm": 2.990016222000122,
      "learning_rate": 5.059021922428331e-06,
      "loss": 2.4576,
      "step": 1600
    },
    {
      "epoch": 2.866779089376054,
      "grad_norm": 2.479146718978882,
      "learning_rate": 2.248454187745925e-06,
      "loss": 2.5048,
      "step": 1700
    }
  ],
  "logging_steps": 100,
  "max_steps": 1779,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 414114113912832.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
